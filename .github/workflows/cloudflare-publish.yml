name: Build, Version, and Deploy to Cloudflare Workers

on:
  push:
    branches:
      - main        # Deploy to production
      - preview     # Deploy to preview
  pull_request:
    branches:
      - main        # Create preview for PRs to main
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  version:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main' && !contains(github.event.head_commit.message, '[skip ci]')
    name: Semantic Versioning
    
    outputs:
      version: ${{ steps.semantic.outputs.new_release_version }}
      released: ${{ steps.semantic.outputs.new_release_published }}
      release-notes: ${{ steps.semantic.outputs.new_release_notes }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Run tests
        run: npm test || echo "No tests configured"
        continue-on-error: true

      - name: Build project
        run: |
          npm run build
          npm run build:worker

      - name: Semantic Release
        id: semantic
        uses: cycjimmy/semantic-release-action@v4
        with:
          semantic_version: 22
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  deploy-production:
    needs: [version]
    if: always() && github.ref == 'refs/heads/main' && (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
    runs-on: ubuntu-latest
    name: Deploy to Production
    environment: production

    steps:
      - name: Checkout (pull latest after semantic-release)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          # Pull the commit created by semantic-release
          ref: main

      - name: Pull latest changes from semantic-release
        run: git pull origin main

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Run tests
        run: npm test || echo "No tests configured"
        continue-on-error: true

      - name: Build Worker with updated version
        run: |
          echo "Building worker with updated package.json version..."
          npm run build:worker
          echo "Built worker version info:"
          echo "Version: $(grep '"version"' package.json | cut -d'"' -f4)" || echo "Version not found in package.json"

      - name: Deploy to Production
        id: deploy
        run: |
          # Create OAuth KV namespaces if they don't exist
          echo "üì¶ Setting up OAuth KV namespaces..."
          if ! npx wrangler kv namespace list | grep -q "OAUTH_KV"; then
            echo "üì¶ Creating OAuth KV namespaces..."
            
            PROD_OUTPUT=$(npx wrangler kv namespace create "OAUTH_KV" 2>&1)
            PROD_KV_ID=$(echo "$PROD_OUTPUT" | grep -o 'id = "[^"]*"' | cut -d'"' -f2)
            
            PREVIEW_OUTPUT=$(npx wrangler kv namespace create "OAUTH_KV" --preview 2>&1)
            PREVIEW_KV_ID=$(echo "$PREVIEW_OUTPUT" | grep -o 'id = "[^"]*"' | cut -d'"' -f2)
            
            echo "‚úÖ Created KV namespaces: Prod=$PROD_KV_ID, Preview=$PREVIEW_KV_ID"
          else
            echo "‚úÖ OAuth KV namespaces already exist"
            PROD_KV_ID=$(npx wrangler kv namespace list | grep "OAUTH_KV" | grep -v "preview" | jq -r '.id')
            PREVIEW_KV_ID=$(npx wrangler kv namespace list | grep "OAUTH_KV" | grep "preview" | jq -r '.id')
            echo "üìã Using existing namespaces: Prod=$PROD_KV_ID, Preview=$PREVIEW_KV_ID"
          fi
          
          # Update wrangler.toml with actual KV namespace IDs
          echo "üîß Updating wrangler.toml with KV namespace IDs..."
          sed -i "s/your-kv-namespace-id/$PROD_KV_ID/g" wrangler.toml
          sed -i "s/your-preview-kv-namespace-id/$PREVIEW_KV_ID/g" wrangler.toml
          
          # Deploy to production
          VERSION="${{ needs.version.outputs.version || 'dev' }}"
          echo "üöÄ Deploying v$VERSION to production..."
          
          # Deploy with better error handling
          if DEPLOY_OUTPUT=$(npx wrangler deploy 2>&1); then
            echo "‚úÖ Deployment successful:"
            echo "$DEPLOY_OUTPUT"
          else
            echo "‚ùå Deployment failed with exit code $?"
            echo "Error output:"
            echo "$DEPLOY_OUTPUT"
            echo "\nüîç Debugging info:"
            echo "Working directory: $(pwd)"
            echo "Files in dist/:"
            ls -la dist/ || echo "No dist directory"
            echo "\nWrangler version:"
            npx wrangler --version
            echo "\nWorker size:"
            du -h dist/worker.js 2>/dev/null || echo "No worker.js found"
            exit 1
          fi
          
          # Extract worker URL
          WORKER_URL=$(echo "$DEPLOY_OUTPUT" | grep -o 'https://[a-zA-Z0-9.-]*\.workers\.dev' | head -1)
          echo "worker-url=$WORKER_URL" >> $GITHUB_OUTPUT
          echo "‚úÖ Deployed to production: $WORKER_URL"
          
          # Upload secrets after deployment
          echo "üîë Uploading secrets to production..."
          echo "ALLOWED_API_KEYS = $ALLOWED_API_KEYS" | npx wrangler secret bulk
          echo "‚úÖ Secrets uploaded successfully"
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          ALLOWED_API_KEYS: ${{ secrets.ALLOWED_API_KEYS }}

      - name: Verify production deployment
        run: |
          WORKER_URL="${{ steps.deploy.outputs.worker-url }}"
          
          if [ -z "$WORKER_URL" ]; then
            echo "‚ùå Failed to capture worker URL"
            exit 1
          fi
          
          # Extract first API key for testing
          FIRST_API_KEY=$(echo "$ALLOWED_API_KEYS" | cut -d',' -f1)
          
          echo "üß™ Verifying production deployment at: $WORKER_URL"
          echo "üîë Using API key for testing: ${FIRST_API_KEY:0:10}..."
          
          # Wait for deployment to propagate
          sleep 30
          
          # Test health endpoint and verify version (accept degraded status)
          echo "Testing health endpoint..."
          HEALTH_RESPONSE=$(curl -s "$WORKER_URL/health" 2>/dev/null) || (echo "‚ùå Health check failed" && exit 1)
          HEALTH_STATUS=$(echo "$HEALTH_RESPONSE" | jq -r '.status // "error"')
          if [[ "$HEALTH_STATUS" == "ok" || "$HEALTH_STATUS" == "degraded" ]]; then
            echo "‚úÖ Health check passed with status: $HEALTH_STATUS"
            echo "   Response: $HEALTH_RESPONSE"
          else
            echo "‚ùå Health check failed with status: $HEALTH_STATUS"
            exit 1
          fi
          
          # Extract and verify version
          DEPLOYED_VERSION=$(echo "$HEALTH_RESPONSE" | grep -o '"version":"[^"]*"' | cut -d'"' -f4)
          EXPECTED_VERSION="${{ needs.version.outputs.version || 'dev' }}"
          
          if [ "$DEPLOYED_VERSION" = "$EXPECTED_VERSION" ]; then
            echo "‚úÖ Version verified: $DEPLOYED_VERSION"
          else
            echo "‚ö†Ô∏è  Version mismatch - deployed: $DEPLOYED_VERSION, expected: $EXPECTED_VERSION"
            echo "‚ÑπÔ∏è  This may indicate the version string in code wasn't updated"
          fi
          
          # Test root endpoint and verify environment
          echo "Testing root endpoint..."
          ROOT_RESPONSE=$(curl -s "$WORKER_URL/")
          ENVIRONMENT=$(echo "$ROOT_RESPONSE" | jq -r '.environment // "unknown"')
          
          if [ "$ENVIRONMENT" = "production" ]; then
            echo "‚úÖ Environment confirmed: $ENVIRONMENT"
          else
            echo "‚ö†Ô∏è  Environment mismatch - expected: production, got: $ENVIRONMENT"
          fi
          
          # Full test suite for production
          echo "Testing tools endpoint..."
          TOOLS_COUNT=$(curl -f "$WORKER_URL/tools" -H "Authorization: Bearer $FIRST_API_KEY" 2>/dev/null | jq '.tools | length') || (echo "‚ùå Tools endpoint failed" && exit 1)
          if [ "$TOOLS_COUNT" -gt 0 ]; then
            echo "‚úÖ Tools endpoint passed - $TOOLS_COUNT tools available"
          else
            echo "‚ùå Tools endpoint failed - no tools found"
            exit 1
          fi
          
          # Test MCP endpoint
          echo "Testing MCP endpoint..."
          AUTH_SUCCESS=$(curl -s -X POST "$WORKER_URL/mcp" \
            -H "Authorization: Bearer $FIRST_API_KEY" \
            -H "Content-Type: application/json" \
            -d '{"jsonrpc": "2.0", "id": 2, "method": "tools/list", "params": {}}')
          
          if echo "$AUTH_SUCCESS" | grep -q -E "(result|tools|jsonrpc)"; then
            echo "‚úÖ MCP endpoint working"
          else
            echo "‚ùå MCP endpoint failed"
            exit 1
          fi
          
          VERSION="${{ needs.version.outputs.version || 'dev' }}"
          RELEASED="${{ needs.version.outputs.released }}"
          
          echo "üéâ All deployment verification tests passed!"
          
          if [ "$RELEASED" = "true" ]; then
            echo "üì¶ New version v$VERSION released and deployed!"
            echo "üìù Release notes: ${{ needs.version.outputs.release-notes }}"
          else
            echo "üîÑ Version v$VERSION deployed to production"
          fi
          
          echo "üöÄ Production server ready at: $WORKER_URL"
        env:
          ALLOWED_API_KEYS: ${{ secrets.ALLOWED_API_KEYS }}

      - name: Verify OAuth integration
        run: |
          WORKER_URL="${{ steps.deploy.outputs.worker-url }}"
          
          echo "üß™ Verifying OAuth integration in main worker at: $WORKER_URL"
          
          # Test OAuth metadata endpoint
          METADATA_RESPONSE=$(curl -s "$WORKER_URL/.well-known/oauth-authorization-server")
          AUTHORIZATION_ENDPOINT=$(echo "$METADATA_RESPONSE" | jq -r '.authorization_endpoint // "missing"')
          
          if [ "$AUTHORIZATION_ENDPOINT" != "missing" ]; then
            echo "‚úÖ OAuth metadata endpoint working"
          else
            echo "‚ùå OAuth metadata endpoint failed"
            echo "Response: $METADATA_RESPONSE"
            exit 1
          fi
          
          # Test OAuth authorization endpoint
          AUTH_RESPONSE=$(curl -s "$WORKER_URL/oauth/authorize?client_id=test&redirect_uri=https://claude.ai/oauth/callback&response_type=code")
          if echo "$AUTH_RESPONSE" | grep -q "Authorize Workflowy Access"; then
            echo "‚úÖ OAuth authorization endpoint working"
          else
            echo "‚ùå OAuth authorization endpoint failed"
            exit 1
          fi
          
          echo "üéâ OAuth integration verification passed!"
          echo ""
          echo "üìã Claude Web Custom Connector Setup:"
          echo "   ‚Ä¢ Name: Workflowy MCP"  
          echo "   ‚Ä¢ Remote MCP server URL: $WORKER_URL/mcp"
          echo "   ‚Ä¢ OAuth Client ID: (leave empty or any value like 'claude-web')"
          echo "   ‚Ä¢ OAuth Client Secret: (leave empty)"
          echo ""
          echo "üîó OAuth Endpoints:"
          echo "   ‚Ä¢ Authorization: $WORKER_URL/oauth/authorize"
          echo "   ‚Ä¢ Token: $WORKER_URL/oauth/token"
          echo "   ‚Ä¢ Metadata: $WORKER_URL/.well-known/oauth-authorization-server"

      - name: Collect Worker Logs with Real-time Output
        continue-on-error: true
        env:
          WORKER_URL: ${{ steps.deploy.outputs.worker-url }}
          ALLOWED_API_KEYS: ${{ secrets.ALLOWED_API_KEYS }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üìã Starting optimized worker log collection..."
          echo "‚ö° Optimizations: 5s init (was 8s), 8s final wait (was 15s), variable request delays"
          
          # Verify we have required variables
          if [ -z "$WORKER_URL" ]; then
            echo "‚ùå WORKER_URL is not set - cannot proceed with log collection"
            exit 1
          fi
          
          if [ -z "$ALLOWED_API_KEYS" ]; then
            echo "‚ùå ALLOWED_API_KEYS is not set - cannot proceed with log collection"
            exit 1
          fi
          
          # Create log files
          touch worker_logs.json workflow_logs.txt
          
          # Extract first API key for testing
          FIRST_API_KEY=$(echo "$ALLOWED_API_KEYS" | cut -d',' -f1)
          
          echo "üìä Log Collection Configuration:"
          echo "   Worker URL: $WORKER_URL"
          echo "   API Key: ${FIRST_API_KEY:0:12}..."
          echo "   Environment: $(echo "$WORKER_URL" | grep -o 'https://[^/]*')"
          echo ""
          
          # Function to make request and capture both response and timing
          make_request() {
            local url="$1"
            local desc="$2"
            local extra_args="$3"
            
            echo "üîÑ $desc"
            echo "   URL: $url"
            
            local start_time=$(date +%s%N)
            local response
            local status_code
            
            if [ -n "$extra_args" ]; then
              response=$(eval "curl -w '%{http_code}' -s $extra_args '$url'")
            else
              response=$(curl -w '%{http_code}' -s "$url")
            fi
            
            status_code="${response: -3}"
            response_body="${response%???}"
            local end_time=$(date +%s%N)
            local duration=$(( (end_time - start_time) / 1000000 ))
            
            echo "   Status: $status_code (${duration}ms)"
            echo "   Response: ${response_body:0:200}$([ ${#response_body} -gt 200 ] && echo '...')"
            echo ""
            
            # Log this request info
            echo "$(date -Iseconds) | $desc | $status_code | ${duration}ms | $url" >> workflow_logs.txt
            
            # Wait briefly for worker logs to be captured (shorter for simple requests)
            if echo "$url" | grep -q "health"; then
              sleep 0.5
            else
              sleep 1
            fi
          }
          
          # Start wrangler tail in background with filtered output
          echo "üì° Starting wrangler tail (will timeout after 35s)..."
          echo "   Tail command: npx wrangler tail --format json"
          (
            timeout 35s npx wrangler tail --format json 2>&1 | while IFS= read -r line; do
              # Save raw log to file
              echo "$line" >> worker_logs.json
              
              # Filter and display only relevant parts
              if echo "$line" | jq -e . >/dev/null 2>&1; then
                # Extract only the important parts from JSON with error suppression
                OUTCOME=$(echo "$line" | jq -r '.outcome // "unknown"' 2>/dev/null)
                WALL_TIME=$(echo "$line" | jq -r '.wallTime // 0' 2>/dev/null)
                CPU_TIME=$(echo "$line" | jq -r '.cpuTime // 0' 2>/dev/null)
                STATUS=$(echo "$line" | jq -r '.event.response.status // "N/A"' 2>/dev/null)
                METHOD=$(echo "$line" | jq -r '.event.request.method // "N/A"' 2>/dev/null)
                URL=$(echo "$line" | jq -r '.event.request.url // "N/A"' 2>/dev/null | sed 's|https://mcp-workflowy-remote.daniel-bca.workers.dev||')
                
                # Extract our structured logs from the logs array
                LOG_MESSAGES=$(echo "$line" | jq -r '.logs[]?.message[]? // empty' 2>/dev/null)
                
                if [ "$OUTCOME" != "null" ] && [ "$OUTCOME" != "unknown" ]; then
                  echo "üìä WORKER: $METHOD $URL | $STATUS | ${WALL_TIME}ms wall, ${CPU_TIME}ms cpu | $OUTCOME"
                fi
                
                # Show our structured log messages (the good stuff!)
                if [ -n "$LOG_MESSAGES" ]; then
                  echo "$LOG_MESSAGES" | while IFS= read -r msg; do
                    if [ -n "$msg" ]; then
                      # Try to parse our structured log
                      if echo "$msg" | jq -e . >/dev/null 2>&1; then
                        TIMESTAMP=$(echo "$msg" | jq -r '.timestamp // ""' 2>/dev/null)
                        LEVEL=$(echo "$msg" | jq -r '.level // "INFO"' 2>/dev/null)
                        MESSAGE=$(echo "$msg" | jq -r '.message // ""' 2>/dev/null)
                        ENDPOINT=$(echo "$msg" | jq -r '.context.endpoint // ""' 2>/dev/null)
                        DURATION=$(echo "$msg" | jq -r '.context.duration // ""' 2>/dev/null)
                        PERF_METRIC=$(echo "$msg" | jq -r '.context.performanceMetric // ""' 2>/dev/null)
                        
                        # Format timestamp to be more readable
                        TIME_ONLY=$(echo "$TIMESTAMP" | sed 's/.*T\([0-9:]\{8\}\).*/\1/' 2>/dev/null)
                        
                        # Show performance metrics specially
                        if [ "$PERF_METRIC" = "true" ]; then
                          echo "‚ö° PERF [$TIME_ONLY] $LEVEL: $MESSAGE ($ENDPOINT) ${DURATION}ms"
                        else
                          echo "üìù LOG  [$TIME_ONLY] $LEVEL: $MESSAGE ($ENDPOINT)"
                        fi
                      else
                        # Check if it looks like a structured log
                        if echo "$msg" | grep -q -E "(level|timestamp|message|context)"; then
                          echo "üìù STRUCT: $msg"
                        else
                          echo "üìú TEXT: $msg"
                        fi
                      fi
                    fi
                  done
                fi
              else
                # Non-JSON line (errors, etc.)
                if [ -n "$line" ]; then
                  echo "‚ö†Ô∏è  RAW: $line"
                fi
              fi
            done
          ) &
          TAIL_PID=$!
          
          # Give wrangler tail time to initialize
          echo "‚è≥ Waiting for wrangler tail to initialize (5 seconds)..."
          sleep 5
          
          # Check if tail process is still running
          if ! kill -0 $TAIL_PID 2>/dev/null; then
            echo "‚ùå Wrangler tail process died during initialization"
            echo "   This might indicate authentication or network issues"
          else
            echo "‚úÖ Wrangler tail process is running (PID: $TAIL_PID)"
          fi
          
          # Make test requests with detailed logging
          echo "üöÄ Starting request sequence to generate worker logs..."
          echo ""
          
          make_request "$WORKER_URL/health" "Health check (no auth)"
          sleep 2
          
          make_request "$WORKER_URL/" "Root endpoint info"
          sleep 2
          
          make_request "$WORKER_URL/tools" "Tools endpoint (with auth)" "-H 'Authorization: Bearer $FIRST_API_KEY'"
          sleep 2
          
          make_request "$WORKER_URL/tools" "Tools endpoint (no auth - should fail)"
          sleep 2
          
          # MCP request
          echo "üîÑ Testing MCP endpoint with tools/list"
          echo "   URL: $WORKER_URL/mcp"
          mcp_start=$(date +%s%N)
          mcp_response=$(curl -w '%{http_code}' -s -X POST "$WORKER_URL/mcp" \
            -H "Authorization: Bearer $FIRST_API_KEY" \
            -H "Content-Type: application/json" \
            -d '{"jsonrpc": "2.0", "id": "log-test-1", "method": "tools/list", "params": {}}')
          mcp_end=$(date +%s%N)
          mcp_duration=$(( (mcp_end - mcp_start) / 1000000 ))
          mcp_status="${mcp_response: -3}"
          mcp_body="${mcp_response%???}"
          echo "   Status: $mcp_status (${mcp_duration}ms)"
          echo "   Response: ${mcp_body:0:300}$([ ${#mcp_body} -gt 300 ] && echo '...')"
          echo ""
          echo "$(date -Iseconds) | MCP tools/list | $mcp_status | ${mcp_duration}ms | $WORKER_URL/mcp" >> workflow_logs.txt
          sleep 3
          
          # Another MCP request to trigger caching
          echo "üîÑ Testing MCP endpoint again (should hit cache)"
          mcp2_start=$(date +%s%N)
          mcp2_response=$(curl -w '%{http_code}' -s -X POST "$WORKER_URL/mcp" \
            -H "Authorization: Bearer $FIRST_API_KEY" \
            -H "Content-Type: application/json" \
            -d '{"jsonrpc": "2.0", "id": "log-test-2", "method": "tools/list", "params": {}}')
          mcp2_end=$(date +%s%N)
          mcp2_duration=$(( (mcp2_end - mcp2_start) / 1000000 ))
          mcp2_status="${mcp2_response: -3}"
          echo "   Status: $mcp2_status (${mcp2_duration}ms) - Should be faster if cached"
          echo ""
          
          # Test error handling
          make_request "$WORKER_URL/nonexistent-endpoint" "Invalid endpoint (should 404)"
          sleep 2
          
          # Wait for final logs
          echo "‚è±Ô∏è  Waiting for final logs to be captured (8 seconds)..."
          sleep 8
          
          # Stop log collection
          echo "üõë Stopping wrangler tail..."
          if kill -0 $TAIL_PID 2>/dev/null; then
            echo "   Sending TERM signal to PID $TAIL_PID"
            kill -TERM $TAIL_PID 2>/dev/null || true
            sleep 3
            
            # Force kill if still running
            if kill -0 $TAIL_PID 2>/dev/null; then
              echo "   Force killing PID $TAIL_PID"
              kill -KILL $TAIL_PID 2>/dev/null || true
            fi
            
            wait $TAIL_PID 2>/dev/null || true
            echo "   ‚úÖ Wrangler tail stopped"
          else
            echo "   ‚ÑπÔ∏è  Wrangler tail process already ended"
          fi
          
          echo ""
          echo "üìä === LOG COLLECTION SUMMARY ==="
          echo ""
          
          # Show what we collected
          if [ -f worker_logs.json ] && [ -s worker_logs.json ]; then
            LOG_COUNT=$(wc -l < worker_logs.json 2>/dev/null || echo "0")
            echo "‚úÖ Wrangler tail captured $LOG_COUNT raw log entries"
            
            # Parse and show summary statistics with safer arithmetic
            REQUESTS=$(grep -c '"outcome":' worker_logs.json 2>/dev/null | head -1 | tr -d '\n' || echo "0")
            REQUESTS=$((REQUESTS + 0))
            ERRORS=$(grep -c '"level":"ERROR"' worker_logs.json 2>/dev/null | head -1 | tr -d '\n' || echo "0")
            ERRORS=$((ERRORS + 0))
            WARNINGS=$(grep -c '"level":"WARN"' worker_logs.json 2>/dev/null | head -1 | tr -d '\n' || echo "0")
            WARNINGS=$((WARNINGS + 0))
            PERF_LOGS=$(grep -c '"performanceMetric":true' worker_logs.json 2>/dev/null | head -1 | tr -d '\n' || echo "0")
            PERF_LOGS=$((PERF_LOGS + 0))
            
            echo "üìä Summary:"
            echo "   ‚Ä¢ Requests processed: $REQUESTS"
            echo "   ‚Ä¢ Performance metrics: $PERF_LOGS"
            echo "   ‚Ä¢ Warnings: $WARNINGS"
            echo "   ‚Ä¢ Errors: $ERRORS"
            
            # Show unique endpoints accessed
            ENDPOINTS=$(grep -o '"endpoint":"[^"]*"' worker_logs.json 2>/dev/null | sort | uniq | head -10)
            if [ -n "$ENDPOINTS" ]; then
              echo "   ‚Ä¢ Endpoints accessed:"
              echo "$ENDPOINTS" | sed 's/"endpoint":"/     - /' | sed 's/"$//'
            fi
            
            # Try to find and show any structured logs from our application
            STRUCTURED_LOGS=$(grep -o '"logs":\[[^]]*\]' worker_logs.json 2>/dev/null | grep -E "(level|timestamp|message)" | head -5 || echo "")
            if [ -n "$STRUCTURED_LOGS" ]; then
              echo ""
              echo "üìù === STRUCTURED APPLICATION LOGS ==="
              echo "$STRUCTURED_LOGS" | while IFS= read -r log_entry; do
                echo "     $log_entry"
              done
            fi
            
            # Show any errors
            if [ "$ERRORS" -gt 0 ]; then
              echo ""
              echo "‚ö†Ô∏è  === ERROR DETAILS ==="
              grep '"level":"ERROR"' worker_logs.json 2>/dev/null | head -3 | while IFS= read -r error_line; do
                ERROR_MSG=$(echo "$error_line" | jq -r '.logs[]?.message[]? // empty' 2>/dev/null | jq -r '.message // "Unknown error"' 2>/dev/null)
                if [ -n "$ERROR_MSG" ]; then
                  echo "     ‚ùå $ERROR_MSG"
                fi
              done
            fi
          else
            echo "‚ö†Ô∏è  No wrangler tail logs captured"
          fi
          
          echo ""
          echo "üìã === WORKFLOW REQUEST LOG ==="
          echo ""
          if [ -f workflow_logs.txt ] && [ -s workflow_logs.txt ]; then
            cat workflow_logs.txt
          else
            echo "No workflow requests logged"
          fi
          
          echo ""
          echo "üì§ Preparing artifacts..."

      - name: Upload Worker Logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: worker-logs-production-${{ github.run_number }}
          path: |
            worker_logs.json
            workflow_logs.txt
            *.log
          retention-days: 7

  deploy-preview:
    if: github.ref == 'refs/heads/preview' || github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    name: Create Preview Version
    environment: preview

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Run tests
        run: npm test || echo "No tests configured"
        continue-on-error: true

      - name: Build Worker
        run: npm run build:worker

      - name: Create Preview Version
        id: deploy-preview
        run: |
          # Create version tag for organization in Cloudflare dashboard
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            VERSION_TAG="pr${{ github.event.number }}"
            echo "üöÄ Creating preview version for PR #${{ github.event.number }}"
          else
            VERSION_TAG="preview"
            echo "üöÄ Creating preview version for preview branch"
          fi
          
          # Note: Preview versions inherit secrets from the deployed worker
          # Secrets are uploaded only during production deployment
          
          # Upload new version with persistent preview alias
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            # For PRs, create both version-specific and pr alias
            DEPLOY_OUTPUT=$(npx wrangler versions upload --tag "$VERSION_TAG" --preview-alias "pr${{ github.event.number }}" --message "Preview: PR #${{ github.event.number }}" 2>&1)
          else
            # For preview branch, always update the "preview" alias
            DEPLOY_OUTPUT=$(npx wrangler versions upload --tag "$VERSION_TAG" --preview-alias "preview" --message "Preview: Phase 0 Critical Operations" 2>&1)
          fi
          echo "$DEPLOY_OUTPUT"
          
          # Extract version ID and preview URLs from wrangler output
          VERSION_ID=$(echo "$DEPLOY_OUTPUT" | grep -o 'Version ID: [a-f0-9-]*' | cut -d' ' -f3)
          VERSION_PREVIEW_URL=$(echo "$DEPLOY_OUTPUT" | grep -o 'Version Preview URL: https://[^[:space:]]*' | cut -d' ' -f4)
          ALIAS_PREVIEW_URL=$(echo "$DEPLOY_OUTPUT" | grep -o 'Alias Preview URL: https://[^[:space:]]*' | cut -d' ' -f4)
          
          # Use alias URL as primary preview URL, fall back to version URL
          if [ -n "$ALIAS_PREVIEW_URL" ]; then
            PREVIEW_URL="$ALIAS_PREVIEW_URL"
          else
            PREVIEW_URL="$VERSION_PREVIEW_URL"
          fi
          
          echo "version-id=$VERSION_ID" >> $GITHUB_OUTPUT
          echo "preview-url=$PREVIEW_URL" >> $GITHUB_OUTPUT
          echo "version-preview-url=$VERSION_PREVIEW_URL" >> $GITHUB_OUTPUT
          echo "alias-preview-url=$ALIAS_PREVIEW_URL" >> $GITHUB_OUTPUT
          echo "version-tag=$VERSION_TAG" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Preview version created: $VERSION_TAG"
          echo "üìù Version ID: $VERSION_ID"
          if [ -n "$ALIAS_PREVIEW_URL" ]; then
            echo "üîó Persistent Alias URL: $ALIAS_PREVIEW_URL"
            echo "üîó Version-specific URL: $VERSION_PREVIEW_URL"
          else
            echo "üîó Preview URL: $PREVIEW_URL"
          fi
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}

      - name: Verify preview version
        run: |
          PREVIEW_URL="${{ steps.deploy-preview.outputs.preview-url }}"
          ALIAS_URL="${{ steps.deploy-preview.outputs.alias-preview-url }}"
          VERSION_URL="${{ steps.deploy-preview.outputs.version-preview-url }}"
          VERSION_ID="${{ steps.deploy-preview.outputs.version-id }}"
          VERSION_TAG="${{ steps.deploy-preview.outputs.version-tag }}"
          
          if [ -z "$PREVIEW_URL" ]; then
            echo "‚ùå Failed to capture preview URL"
            exit 1
          fi
          
          # Use production API keys since it's the same worker, just a different version
          FIRST_API_KEY=$(echo "$ALLOWED_API_KEYS" | cut -d',' -f1)
          
          echo "üß™ Verifying preview version: $VERSION_TAG"
          echo "üìù Version ID: $VERSION_ID"
          if [ -n "$ALIAS_URL" ]; then
            echo "üîó Persistent Alias: $ALIAS_URL"
            echo "üîó Version-specific: $VERSION_URL"
          else
            echo "üîó Preview URL: $PREVIEW_URL"
          fi
          
          # Wait for version to propagate
          sleep 25
          
          # Test health endpoint (accept degraded status)
          echo "Testing health endpoint..."
          HEALTH_RESPONSE=$(curl -s "$PREVIEW_URL/health" 2>/dev/null) || (echo "‚ùå Health check failed" && exit 1)
          HEALTH_STATUS=$(echo "$HEALTH_RESPONSE" | jq -r '.status // "error"')
          if [[ "$HEALTH_STATUS" == "ok" || "$HEALTH_STATUS" == "degraded" ]]; then
            echo "‚úÖ Health check passed with status: $HEALTH_STATUS"
          else
            echo "‚ùå Health check failed with status: $HEALTH_STATUS"
            exit 1
          fi
          
          # Test basic functionality
          echo "Testing basic authentication..."
          AUTH_TEST=$(curl -s "$PREVIEW_URL/tools" -H "Authorization: Bearer $FIRST_API_KEY")
          if echo "$AUTH_TEST" | grep -q "tools"; then
            echo "‚úÖ Preview version working"
          else
            echo "‚ùå Preview version failed"
            exit 1
          fi
          
          echo "üéâ Preview version verification passed!"
          if [ -n "$ALIAS_URL" ]; then
            echo "üîó Stable Preview URL: $ALIAS_URL"
            echo "üîó Version-specific URL: $VERSION_URL"
            echo "üì¶ Version: $VERSION_TAG ($VERSION_ID)"
            echo ""
            echo "‚ÑπÔ∏è  The 'preview' alias always points to the latest preview branch."
            echo "‚ÑπÔ∏è  Production remains unchanged until merged to main."
          else
            echo "üîó Preview URL: $PREVIEW_URL"
            echo "üì¶ Version: $VERSION_TAG ($VERSION_ID)"
          fi
        env:
          ALLOWED_API_KEYS: ${{ secrets.ALLOWED_API_KEYS }}

      - name: Collect Preview Worker Logs
        continue-on-error: true
        run: |
          echo "üìã Starting preview worker log collection..."
          
          PREVIEW_URL="${{ steps.deploy-preview.outputs.preview-url }}"
          VERSION_TAG="${{ steps.deploy-preview.outputs.version-tag }}"
          
          # Create empty log file first
          touch preview_logs.json
          
          # Verify wrangler is available
          if ! command -v npx >/dev/null 2>&1; then
            echo "‚ö†Ô∏è  npx not available, skipping preview log collection"
            exit 0
          fi
          
          # Start wrangler tail in background to capture logs
          if timeout 35s npx wrangler tail --format json >> preview_logs.json & then
            TAIL_PID=$!
          else
            echo "‚ö†Ô∏è  Failed to start wrangler tail, skipping preview log collection"
            exit 0
          fi
          
          echo "üì° Started preview log collection (PID: $TAIL_PID)"
          
          # Give logs a moment to start
          sleep 3
          
          # Make test requests to generate logs
          echo "üß™ Making test requests to preview worker..."
          
          # Test health endpoint
          echo "Testing preview health endpoint..."
          curl -s "$PREVIEW_URL/health" > /dev/null
          
          # Test tools endpoint with auth
          echo "Testing preview authenticated endpoint..."
          curl -s "$PREVIEW_URL/tools" -H "Authorization: Bearer $FIRST_API_KEY" > /dev/null
          
          # Test error handling
          echo "Testing preview error handling..."
          curl -s "$PREVIEW_URL/invalid" > /dev/null
          
          # Wait for logs to be captured
          echo "‚è±Ô∏è  Waiting for preview logs to be captured..."
          sleep 10
          
          # Stop log collection gracefully
          kill $TAIL_PID 2>/dev/null || true
          sleep 2
          wait $TAIL_PID 2>/dev/null || true
          
          echo "üîç Analyzing preview logs..."
          
          if [ -f preview_logs.json ] && [ -s preview_logs.json ]; then
            echo "‚úÖ Preview logs collected successfully!"
            
            LOG_COUNT=$(wc -l < preview_logs.json || echo "0")
            echo "  ‚Ä¢ Total preview log entries: $LOG_COUNT"
            
            if [ "$LOG_COUNT" -gt 0 ]; then
              # Check environment is set correctly for preview
              PREVIEW_ENV_LOGS=$(grep -c '"environment":"preview"' preview_logs.json || echo "0")
              echo "  ‚Ä¢ Preview environment logs: $PREVIEW_ENV_LOGS"
              
              # Check for performance features
              CACHE_LOGS=$(grep -c 'cacheOperation' preview_logs.json || echo "0")
              DEDUP_LOGS=$(grep -c 'Deduplicating' preview_logs.json || echo "0")
              RETRY_LOGS=$(grep -c 'Retry attempt' preview_logs.json || echo "0")
              
              echo "  ‚Ä¢ Cache operations: $CACHE_LOGS"
              echo "  ‚Ä¢ Deduplication: $DEDUP_LOGS"
              echo "  ‚Ä¢ Retry attempts: $RETRY_LOGS"
              
              # Show preview-specific logs
              echo "\nüìù Preview log sample:"
              head -3 preview_logs.json | jq -r '. | "[" + .timestamp + "] " + .level + ": " + .message' 2>/dev/null || head -3 preview_logs.json
            fi
          else
            echo "‚ö†Ô∏è  No preview logs collected"
          fi
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          ALLOWED_API_KEYS: ${{ secrets.ALLOWED_API_KEYS }}

      - name: Upload Preview Worker Logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: worker-logs-preview-${{ github.run_number }}
          path: |
            preview_logs.json
            *.log
          retention-days: 7